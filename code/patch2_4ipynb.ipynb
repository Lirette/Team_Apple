{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "patch2_4ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QScwR_sTi7xG"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1mUDx4uFpbS6jrD7lN-P7F7saefP_QJ31?usp=sharing)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMDP-YEodfnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "835f384c-887d-4ff1-b6c2-0d779126bebf"
      },
      "source": [
        "# Import required packages\n",
        "!python -m spacy download fr_core_news_sm\n",
        "#import fr_core_news_sm\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        " "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fr_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7 MB 520 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Building wheels for collected packages: fr-core-news-sm\n",
            "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-py3-none-any.whl size=14727026 sha256=2a5abd0603f98731f6f129668ee43e7ca6fc7753e6bfb45b6760bfe803c46d0d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p92bszlh/wheels/c9/a6/ea/0778337c34660027ee67ef3a91fb9d3600b76777a912ea1c24\n",
            "Successfully built fr-core-news-sm\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5YYODCIdjJs"
      },
      "source": [
        "# Import additional packages\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "import string\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "from spacy.lang.fr.stop_words import STOP_WORDS\n",
        "from spacy.lang.fr.examples import sentences \n",
        "from spacy.lang.fr import French\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "uAQg9ugrdrS6",
        "outputId": "90aef9a2-cdc9-48ea-b425-b92092880f50"
      },
      "source": [
        "path = \"https://raw.githubusercontent.com/Lirette2/DMML2021_Apple/main/data/training_data.csv\"\n",
        "\n",
        "df = pd.read_csv(path, index_col=0)\n",
        "df.head()\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nous dûmes nous excuser des propos que nous eû...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Et, paradoxalement, boire froid n'est pas la b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ce n'est pas étonnant, car c'est une saison my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Le corps de Golo lui-même, d'une essence aussi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             sentence\n",
              "id                                                   \n",
              "0   Nous dûmes nous excuser des propos que nous eû...\n",
              "1   Vous ne pouvez pas savoir le plaisir que j'ai ...\n",
              "2   Et, paradoxalement, boire froid n'est pas la b...\n",
              "3   Ce n'est pas étonnant, car c'est une saison my...\n",
              "4   Le corps de Golo lui-même, d'une essence aussi..."
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvPY_lQydtnp",
        "outputId": "783aa88e-88f4-45e1-e5bb-ea1a07cc9f41"
      },
      "source": [
        "df.info()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 4800 entries, 0 to 4799\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   sentence    4800 non-null   object\n",
            " 1   difficulty  4800 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 112.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BouzxX3ndvik",
        "outputId": "ea775467-d1f7-4810-8cb6-aa027d35a841"
      },
      "source": [
        "# Base rate: the data-set is a bit balanced!\n",
        "df.difficulty.value_counts()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "A1    813\n",
              "C2    807\n",
              "C1    798\n",
              "B1    795\n",
              "A2    795\n",
              "B2    792\n",
              "Name: difficulty, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "OxATHOC2dxPh",
        "outputId": "292a382c-f804-4469-b00f-9856dcb58b1e"
      },
      "source": [
        "difficulty_count = df.groupby(\"difficulty\").count()\n",
        "plt.bar(difficulty_count.index.values, difficulty_count[\"sentence\"])\n",
        "plt.xlabel(\"Difficulty\")\n",
        "plt.ylabel(\"Number of Sentences\")\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWAbLqJpfA0F",
        "outputId": "5fd3f402-491a-4a80-d308-1eebd20f05fc"
      },
      "source": [
        "round(df.difficulty.value_counts().max()/ len(df), 4)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1694"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daGEGXdFfESw"
      },
      "source": [
        "### tokening the date with spaCy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cLA0BmpVfJEI",
        "outputId": "fe9ddd6e-15c6-45be-a886-b86d14a3a973"
      },
      "source": [
        "# Create a list of punctuation marks\n",
        "punctuations = string.punctuation\n",
        "punctuations"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQBHplsRfLXk",
        "outputId": "bdf44ef9-29a3-4188-cb7e-072dfa8be959"
      },
      "source": [
        "# Create a list of stopwords\n",
        "#stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
        "stop_words = spacy.lang.fr.stop_words.STOP_WORDS\n",
        "\n",
        "list(stop_words)[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['seulement',\n",
              " 'pu',\n",
              " 'pourquoi',\n",
              " 'minimale',\n",
              " 'anterieur',\n",
              " 'certaine',\n",
              " 'chères',\n",
              " 'seul',\n",
              " 'houp',\n",
              " 'tel']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC6QJzQffNkL"
      },
      "source": [
        "# Load French language model\n",
        "import fr_core_news_sm\n",
        "#sp = spacy.load('en_core_web_sm')\n",
        "sp = fr_core_news_sm.load()\n",
        "\n",
        "# Create tokenizer function\n",
        "def spacy_tokenizer(sentence):\n",
        "    # Create token object, which is used to create documents with linguistic annotations.\n",
        "    mytokens = sp(sentence)\n",
        "\n",
        "    # Lemmatize each token and convert each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() for word in mytokens ]\n",
        "    ## alternative way\n",
        "    # mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "\n",
        "    # Remove stop words and punctuation\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    # Return preprocessed list of tokens\n",
        "    return mytokens\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAbdvIavfP5G",
        "outputId": "e388410d-46c2-4130-8749-c942e4644568"
      },
      "source": [
        "# Example\n",
        "#New_sentence = df[\"sentence\"].sample()\n",
        "New_sentence = df[\"sentence\"].head()\n",
        "New_sentence.values[0]\n",
        "spacy_tokenizer(New_sentence.values[0])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['coût',\n",
              " 'kilométrique',\n",
              " 'réel',\n",
              " 'pouvoir',\n",
              " 'diverger',\n",
              " 'sensiblemer',\n",
              " 'valeur',\n",
              " 'moyenner',\n",
              " 'fonction',\n",
              " 'moyen',\n",
              " 'transport',\n",
              " 'utiliser',\n",
              " 'taux',\n",
              " 'occupation',\n",
              " 'taux',\n",
              " 'remplissage',\n",
              " 'infrastructure',\n",
              " 'utiliser',\n",
              " 'topographie',\n",
              " 'ligne',\n",
              " 'flux',\n",
              " 'trafic',\n",
              " 'etc.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB7SbUOafRXZ"
      },
      "source": [
        "#### **** ***************** **** ####\n",
        "#### **** RAW TEXT FEATURES **** ####\n",
        "#### **** ***************** **** ####\n",
        "\n",
        "# Count tokens per sentence\n",
        "def count_token(sent):\n",
        "  return(len(spacy_tokenizer(sent))) #spacy_tokenizer() to get tokens, len() to count them\n",
        "\n",
        "# Count raw words per sentence\n",
        "def count_words(sent):\n",
        "  return(len(sent.split())) #split() gives us individual words, len() counts them\n",
        "\n",
        "#Get average character length of word\n",
        "def count_avg_word_character(sent):\n",
        "  words = sent.split()\n",
        "  return(sum(len(word) for word in words) / len(words))\n",
        "\n",
        "def count_avg_token_character(sent):\n",
        "  words = spacy_tokenizer(sent)\n",
        "  if len(words) == 0:\n",
        "    return(0)\n",
        "  else:\n",
        "    return(sum(len(word) for word in words) / len(words))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Czbuy7JkXJnB"
      },
      "source": [
        "#### **** **************** **** ####\n",
        "#### **** LEXICAL FEATURES **** ####\n",
        "#### **** **************** **** ####\n",
        "\n",
        "# Lexical Diversity\n",
        "def lex_div_word(sent):\n",
        "  total_number_word = len(sent.split())\n",
        "  unique = set(sent.split())\n",
        "  return(len(unique)/total_number_word)\n",
        "#We don't apply for token, as the goal of the tokenzization is to be left with \n",
        "#unique tokens\n",
        "#For tokens, we should apply to the whole text as done by tfidf_vector\n",
        "\n",
        "# Lexical Density\n",
        "def lex_den_tokens(sent):\n",
        "  st = spacy_tokenizer(sent)\n",
        "  if len(st) == 0:\n",
        "    return(0)\n",
        "  else:\n",
        "    string = \" \".join([str(item) for item in st])\n",
        "    x = sp(string)\n",
        "    counter = 0 \n",
        "    for token in x:\n",
        "      if token.pos_ == \"NOUN\" or token.pos_ == \"ADJ\" or token.pos_ == \"VERB\" or token.pos_ == \"ADV\":\n",
        "        counter = counter + 1\n",
        "    return(counter/len(st))\n",
        "\n",
        "def lex_den_words(sent):\n",
        "  x = sp(sent)\n",
        "  counter = 0 \n",
        "  for token in x:\n",
        "    if token.pos_ == \"NOUN\" or token.pos_ == \"ADJ\" or token.pos_ == \"VERB\" or token.pos_ == \"ADV\":\n",
        "      counter = counter + 1\n",
        "  return(counter/len(x))\n",
        "\n",
        "# Words NOT in frequent list\n",
        "path = \"https://raw.githubusercontent.com/Lirette2/DMML2021_Apple/main/data/list_words.csv\"\n",
        "words = pd.read_csv(path, index_col=0)\n",
        "\n",
        "\n",
        "def words_list(sent):\n",
        "  unique = set(sent.split())\n",
        "  counter = 0\n",
        "  for word_in_sentence in unique:\n",
        "    for word_in_list in words.Mots:\n",
        "      if word_in_sentence == word_in_list:\n",
        "        counter = counter + 1\n",
        "        break#we stop comparing once the word in found, to make it faster\n",
        "  return(1-(counter/len(unique)))\n",
        "\n",
        "\n",
        "def token_list(sent):\n",
        "  unique = spacy_tokenizer(sent)\n",
        "  if len(unique) == 0:\n",
        "    return(0)\n",
        "  else:\n",
        "    counter = 0\n",
        "    for word_in_sentence in unique:\n",
        "      for word_in_list in words.Mots:\n",
        "        if word_in_sentence == word_in_list:\n",
        "          counter = counter + 1\n",
        "          break#we stop comparing once the word in found, to make it faster\n",
        "    return(1-(counter/len(unique)))\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qJEbTBFhM3J7",
        "outputId": "c98e5e47-064f-47f3-efb6-eeea0ebbf67b"
      },
      "source": [
        "raw_word_count = pd.Series(df.sentence.apply(count_words),name=\"raw_word_count\")\n",
        "token_count = pd.Series(df.sentence.apply(count_token),name=\"token_count\")\n",
        "avg_chr_word = pd.Series(df.sentence.apply(count_avg_word_character),name=\"avg_chr_word\")\n",
        "avg_chr_token = pd.Series(df.sentence.apply(count_avg_token_character),name=\"avg_chr_token\")\n",
        "diversity_word = pd.Series(df.sentence.apply(lex_div_word),name=\"diversity_word\")\n",
        "density_word = pd.Series(df.sentence.apply(lex_den_words),name=\"density_word\")\n",
        "density_token = pd.Series(df.sentence.apply(lex_den_tokens),name=\"density_token\")\n",
        "freq_word_list = pd.Series(df.sentence.apply(words_list),name=\"freq_word_list\")\n",
        "freq_token_list = pd.Series(df.sentence.apply(token_list),name=\"freq_token_list\")\n",
        "\n",
        "new_df = pd.concat([df,raw_word_count,token_count,avg_chr_word,avg_chr_token,\n",
        "                    diversity_word,density_word,density_token,freq_word_list,freq_token_list],axis=1)\n",
        "new_df"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>raw_word_count</th>\n",
              "      <th>token_count</th>\n",
              "      <th>avg_chr_word</th>\n",
              "      <th>avg_chr_token</th>\n",
              "      <th>diversity_word</th>\n",
              "      <th>density_word</th>\n",
              "      <th>density_token</th>\n",
              "      <th>freq_word_list</th>\n",
              "      <th>freq_token_list</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
              "      <td>C1</td>\n",
              "      <td>38</td>\n",
              "      <td>23</td>\n",
              "      <td>5.736842</td>\n",
              "      <td>7.434783</td>\n",
              "      <td>0.763158</td>\n",
              "      <td>0.488889</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.793103</td>\n",
              "      <td>0.739130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
              "      <td>A1</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>4.250000</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Le test de niveau en français est sur le site ...</td>\n",
              "      <td>A1</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>4.153846</td>\n",
              "      <td>5.833333</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>A1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>4.125000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
              "      <td>B1</td>\n",
              "      <td>34</td>\n",
              "      <td>18</td>\n",
              "      <td>5.176471</td>\n",
              "      <td>5.611111</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>C'est pourquoi, il décida de remplacer les hab...</td>\n",
              "      <td>B2</td>\n",
              "      <td>26</td>\n",
              "      <td>12</td>\n",
              "      <td>5.384615</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.576923</td>\n",
              "      <td>0.416667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>Il avait une de ces pâleurs splendides qui don...</td>\n",
              "      <td>C1</td>\n",
              "      <td>21</td>\n",
              "      <td>10</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.700000</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>Et le premier samedi de chaque mois, venez ren...</td>\n",
              "      <td>A2</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>4.785714</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>Les coûts liés à la journalisation n'étant pas...</td>\n",
              "      <td>C2</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>6.093750</td>\n",
              "      <td>8.500000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.540541</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.678571</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>Sur le sable, la mer haletait de toute la resp...</td>\n",
              "      <td>C2</td>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "      <td>4.647059</td>\n",
              "      <td>6.250000</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4800 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  ... freq_token_list\n",
              "id                                                       ...                \n",
              "0     Les coûts kilométriques réels peuvent diverger...  ...        0.739130\n",
              "1     Le bleu, c'est ma couleur préférée mais je n'a...  ...        0.200000\n",
              "2     Le test de niveau en français est sur le site ...  ...        0.666667\n",
              "3              Est-ce que ton mari est aussi de Boston?  ...        0.500000\n",
              "4     Dans les écoles de commerce, dans les couloirs...  ...        0.500000\n",
              "...                                                 ...  ...             ...\n",
              "4795  C'est pourquoi, il décida de remplacer les hab...  ...        0.416667\n",
              "4796  Il avait une de ces pâleurs splendides qui don...  ...        0.600000\n",
              "4797  Et le premier samedi de chaque mois, venez ren...  ...        0.333333\n",
              "4798  Les coûts liés à la journalisation n'étant pas...  ...        0.687500\n",
              "4799  Sur le sable, la mer haletait de toute la resp...  ...        0.375000\n",
              "\n",
              "[4800 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ywssd_eDU5hy",
        "outputId": "564a38b5-cf18-4dd0-fdc7-2083e16d00b4"
      },
      "source": [
        "#Scale the data\n",
        "scaler = MinMaxScaler()\n",
        "col_to_scale = [\"raw_word_count\",\"token_count\",\"avg_chr_word\",\"avg_chr_token\"]\n",
        "#no need for the others because they already are on a scale from 0 to 1\n",
        "new_df[col_to_scale]= scaler.fit_transform(new_df[col_to_scale])\n",
        "\n",
        "new_df "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>raw_word_count</th>\n",
              "      <th>token_count</th>\n",
              "      <th>avg_chr_word</th>\n",
              "      <th>avg_chr_token</th>\n",
              "      <th>diversity_word</th>\n",
              "      <th>density_word</th>\n",
              "      <th>density_token</th>\n",
              "      <th>freq_word_list</th>\n",
              "      <th>freq_token_list</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
              "      <td>C1</td>\n",
              "      <td>0.140152</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.339713</td>\n",
              "      <td>0.619565</td>\n",
              "      <td>0.763158</td>\n",
              "      <td>0.488889</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.793103</td>\n",
              "      <td>0.739130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
              "      <td>A1</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.204545</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Le test de niveau en français est sur le site ...</td>\n",
              "      <td>A1</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.195804</td>\n",
              "      <td>0.486111</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>A1</td>\n",
              "      <td>0.026515</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.193182</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
              "      <td>B1</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.144</td>\n",
              "      <td>0.288770</td>\n",
              "      <td>0.467593</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>C'est pourquoi, il décida de remplacer les hab...</td>\n",
              "      <td>B2</td>\n",
              "      <td>0.094697</td>\n",
              "      <td>0.096</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.576923</td>\n",
              "      <td>0.416667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>Il avait une de ces pâleurs splendides qui don...</td>\n",
              "      <td>C1</td>\n",
              "      <td>0.075758</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.242424</td>\n",
              "      <td>0.475000</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>Et le premier samedi de chaque mois, venez ren...</td>\n",
              "      <td>A2</td>\n",
              "      <td>0.049242</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.253247</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>Les coûts liés à la journalisation n'étant pas...</td>\n",
              "      <td>C2</td>\n",
              "      <td>0.117424</td>\n",
              "      <td>0.128</td>\n",
              "      <td>0.372159</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.540541</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.678571</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>Sur le sable, la mer haletait de toute la resp...</td>\n",
              "      <td>C2</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.064</td>\n",
              "      <td>0.240642</td>\n",
              "      <td>0.520833</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4800 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  ... freq_token_list\n",
              "id                                                       ...                \n",
              "0     Les coûts kilométriques réels peuvent diverger...  ...        0.739130\n",
              "1     Le bleu, c'est ma couleur préférée mais je n'a...  ...        0.200000\n",
              "2     Le test de niveau en français est sur le site ...  ...        0.666667\n",
              "3              Est-ce que ton mari est aussi de Boston?  ...        0.500000\n",
              "4     Dans les écoles de commerce, dans les couloirs...  ...        0.500000\n",
              "...                                                 ...  ...             ...\n",
              "4795  C'est pourquoi, il décida de remplacer les hab...  ...        0.416667\n",
              "4796  Il avait une de ces pâleurs splendides qui don...  ...        0.600000\n",
              "4797  Et le premier samedi de chaque mois, venez ren...  ...        0.333333\n",
              "4798  Les coûts liés à la journalisation n'étant pas...  ...        0.687500\n",
              "4799  Sur le sable, la mer haletait de toute la resp...  ...        0.375000\n",
              "\n",
              "[4800 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMiQYs9XfU0I"
      },
      "source": [
        "## classification of level using logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "4mcl9ptvfXzi",
        "outputId": "11011304-5762-4ac8-c604-2a3953bc1243"
      },
      "source": [
        "# Select features\n",
        "X = new_df[[\"sentence\",\"raw_word_count\",\"token_count\",\"avg_chr_word\",\"avg_chr_token\",\n",
        "                    \"diversity_word\",\"density_word\",\"density_token\",\"freq_word_list\",\n",
        "            \"freq_token_list\"]]# the features we want to analyze\n",
        "\n",
        "ylabels = new_df['difficulty'] # the labels, or answers, we want to test against\n",
        "\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=1234, stratify=ylabels)\n",
        "\n",
        "X_train"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>raw_word_count</th>\n",
              "      <th>token_count</th>\n",
              "      <th>avg_chr_word</th>\n",
              "      <th>avg_chr_token</th>\n",
              "      <th>diversity_word</th>\n",
              "      <th>density_word</th>\n",
              "      <th>density_token</th>\n",
              "      <th>freq_word_list</th>\n",
              "      <th>freq_token_list</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>962</th>\n",
              "      <td>Le réalisateur m'a d'abord demandé de me mettr...</td>\n",
              "      <td>0.037879</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.645833</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1886</th>\n",
              "      <td>Après quelques mois de cette pauvreté noble, a...</td>\n",
              "      <td>0.109848</td>\n",
              "      <td>0.112</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.517857</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.586207</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2721</th>\n",
              "      <td>L'indicateur n'était que de 40% chez les femme...</td>\n",
              "      <td>0.034091</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.245455</td>\n",
              "      <td>0.483333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1025</th>\n",
              "      <td>L'objectif de ce type de voyage est d'être act...</td>\n",
              "      <td>0.094697</td>\n",
              "      <td>0.096</td>\n",
              "      <td>0.241259</td>\n",
              "      <td>0.527778</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.482759</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.416667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4048</th>\n",
              "      <td>Et, en France, beaucoup moins de filles que de...</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.276680</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.384615</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3693</th>\n",
              "      <td>Je vais prendre ma douche dans ma salle-de-bain.</td>\n",
              "      <td>0.026515</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.284091</td>\n",
              "      <td>0.645833</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3408</th>\n",
              "      <td>Après l'éruption de 1754, la plus grosse connu...</td>\n",
              "      <td>0.132576</td>\n",
              "      <td>0.128</td>\n",
              "      <td>0.275253</td>\n",
              "      <td>0.546875</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.655172</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4289</th>\n",
              "      <td>Léonard est initié par Verrocchio aux nombreus...</td>\n",
              "      <td>0.117424</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.369318</td>\n",
              "      <td>0.644444</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.472222</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.866667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3312</th>\n",
              "      <td>On en trouve des exemples dans l'ouvrage \"L'in...</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.432727</td>\n",
              "      <td>0.694444</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>On peut aussi aller au théâtre, dans les musée...</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.189394</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3840 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  ...  freq_token_list\n",
              "id                                                       ...                 \n",
              "962   Le réalisateur m'a d'abord demandé de me mettr...  ...         0.500000\n",
              "1886  Après quelques mois de cette pauvreté noble, a...  ...         0.714286\n",
              "2721  L'indicateur n'était que de 40% chez les femme...  ...         0.800000\n",
              "1025  L'objectif de ce type de voyage est d'être act...  ...         0.416667\n",
              "4048  Et, en France, beaucoup moins de filles que de...  ...         0.300000\n",
              "...                                                 ...  ...              ...\n",
              "3693   Je vais prendre ma douche dans ma salle-de-bain.  ...         0.500000\n",
              "3408  Après l'éruption de 1754, la plus grosse connu...  ...         0.625000\n",
              "4289  Léonard est initié par Verrocchio aux nombreus...  ...         0.866667\n",
              "3312  On en trouve des exemples dans l'ouvrage \"L'in...  ...         0.800000\n",
              "269   On peut aussi aller au théâtre, dans les musée...  ...         0.400000\n",
              "\n",
              "[3840 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYn0f20UfZBz",
        "outputId": "f6abbb89-0db3-47a2-95c1-37cd83731f47"
      },
      "source": [
        "y_train\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "962     B1\n",
              "1886    C1\n",
              "2721    A2\n",
              "1025    B1\n",
              "4048    B2\n",
              "        ..\n",
              "3693    A1\n",
              "3408    B1\n",
              "4289    C2\n",
              "3312    C2\n",
              "269     A1\n",
              "Name: difficulty, Length: 3840, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iaGbtXRfTze"
      },
      "source": [
        "# Evaluate the model\n",
        "def evaluate(test, pred):\n",
        "  precision = precision_score(test, pred,average=None)\n",
        "  recall = recall_score(test, pred, average=None)\n",
        "  f1= f1_score(test, pred, average=None)\n",
        "  print(f'CONFUSION MATRIX:\\n{confusion_matrix(test, pred)}')\n",
        "  print(f\"ACCURACY SCORE:\\n{accuracy_score(test, pred) :.4f}\")\n",
        "  print(f'CLASSIFICATION REPORT:')\n",
        "  print(\"Precision:\\t {0:4f}\".format(precision_score(test, pred,average=\"macro\"))) \n",
        "  print(\"Recall:\\t {0:4f}\".format(recall_score(test, pred, average=\"macro\")))\n",
        "  print(\"F1_Score:\\t {0:4f}\".format(f1_score(test, pred, average=\"macro\")))\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF7mS7lLfaXk",
        "outputId": "c649d12e-f35f-48ac-e270-29bed7f2cc16"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Define classifier\n",
        "classifier = LogisticRegression(multi_class=\"multinomial\",max_iter=1000)\n",
        "\n",
        "#Vectorizer\n",
        "tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer)\n",
        "\n",
        "#Column Transformer (to apply vectorizer to the right column)\n",
        "column_transformer = ColumnTransformer(\n",
        "    [(\"tfidf\", tfidf_vector, \"sentence\")],\n",
        "    remainder=\"passthrough\")\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([(\"tfidf\",column_transformer),(\"classifier\", classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n",
        "# Predictions\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "# Evaluation - test set\n",
        "evaluate(y_test, y_pred)\n",
        "\n",
        "#just token: 0.4531\n",
        "#just words: 0.4729\n",
        "#everything: 0.4823"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[101  27  24   8   3   0]\n",
            " [ 43  60  41   7   8   0]\n",
            " [ 20  41  62  21   5  10]\n",
            " [  4   8  13  73  31  29]\n",
            " [  3   2  11  34  77  33]\n",
            " [  3   0  13  24  31  90]]\n",
            "ACCURACY SCORE:\n",
            "0.4823\n",
            "CLASSIFICATION REPORT:\n",
            "Precision:\t 0.480458\n",
            "Recall:\t 0.481535\n",
            "F1_Score:\t 0.480457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Submission data\n",
        "\n",
        "path = \"https://raw.githubusercontent.com/Lirette2/DMML2021_Apple/main/data/unlabelled_test_data.csv\"\n",
        "sub_df = pd.read_csv(path, index_col=0)\n",
        "\n",
        "raw_word_count = pd.Series(sub_df.sentence.apply(count_words),name=\"raw_word_count\")\n",
        "token_count = pd.Series(sub_df.sentence.apply(count_token),name=\"token_count\")\n",
        "avg_chr_word = pd.Series(sub_df.sentence.apply(count_avg_word_character),name=\"avg_chr_word\")\n",
        "avg_chr_token = pd.Series(sub_df.sentence.apply(count_avg_token_character),name=\"avg_chr_token\")\n",
        "diversity_word = pd.Series(sub_df.sentence.apply(lex_div_word),name=\"diversity_word\")\n",
        "density_word = pd.Series(sub_df.sentence.apply(lex_den_words),name=\"density_word\")\n",
        "density_token = pd.Series(sub_df.sentence.apply(lex_den_tokens),name=\"density_token\")\n",
        "freq_word_list = pd.Series(sub_df.sentence.apply(words_list),name=\"freq_word_list\")\n",
        "freq_token_list = pd.Series(sub_df.sentence.apply(token_list),name=\"freq_token_list\")\n",
        "\n",
        "new_sub_df = pd.concat([sub_df,raw_word_count,token_count,avg_chr_word,avg_chr_token,\n",
        "                    diversity_word,density_word,density_token,freq_word_list,freq_token_list],axis=1)\n",
        "new_sub_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "7oCiaJZI-qJj",
        "outputId": "c6949501-8763-4731-87ab-75e417e2e8a2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>raw_word_count</th>\n",
              "      <th>token_count</th>\n",
              "      <th>avg_chr_word</th>\n",
              "      <th>avg_chr_token</th>\n",
              "      <th>diversity_word</th>\n",
              "      <th>density_word</th>\n",
              "      <th>density_token</th>\n",
              "      <th>freq_word_list</th>\n",
              "      <th>freq_token_list</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nous dûmes nous excuser des propos que nous eû...</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>4.714286</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Et, paradoxalement, boire froid n'est pas la b...</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>5.555556</td>\n",
              "      <td>6.600000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ce n'est pas étonnant, car c'est une saison my...</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>5.222222</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Le corps de Golo lui-même, d'une essence aussi...</td>\n",
              "      <td>72</td>\n",
              "      <td>31</td>\n",
              "      <td>5.402778</td>\n",
              "      <td>7.322581</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.418605</td>\n",
              "      <td>0.612903</td>\n",
              "      <td>0.543860</td>\n",
              "      <td>0.677419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>C'est un phénomène qui trouve une accélération...</td>\n",
              "      <td>22</td>\n",
              "      <td>9</td>\n",
              "      <td>5.090909</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.954545</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>Je vais parler au serveur et voir si on peut d...</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>4.076923</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>Il n'était pas comme tant de gens qui par pare...</td>\n",
              "      <td>75</td>\n",
              "      <td>34</td>\n",
              "      <td>5.266667</td>\n",
              "      <td>7.117647</td>\n",
              "      <td>0.826667</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>0.852941</td>\n",
              "      <td>0.596774</td>\n",
              "      <td>0.441176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>Ils deviennent dangereux pour notre économie.</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>Son succès a généré beaucoup de réactions néga...</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>5.625000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  ...  freq_token_list\n",
              "id                                                       ...                 \n",
              "0     Nous dûmes nous excuser des propos que nous eû...  ...         0.250000\n",
              "1     Vous ne pouvez pas savoir le plaisir que j'ai ...  ...         0.000000\n",
              "2     Et, paradoxalement, boire froid n'est pas la b...  ...         0.400000\n",
              "3     Ce n'est pas étonnant, car c'est une saison my...  ...         0.666667\n",
              "4     Le corps de Golo lui-même, d'une essence aussi...  ...         0.677419\n",
              "...                                                 ...  ...              ...\n",
              "1195  C'est un phénomène qui trouve une accélération...  ...         0.555556\n",
              "1196  Je vais parler au serveur et voir si on peut d...  ...         0.333333\n",
              "1197  Il n'était pas comme tant de gens qui par pare...  ...         0.441176\n",
              "1198      Ils deviennent dangereux pour notre économie.  ...         0.666667\n",
              "1199  Son succès a généré beaucoup de réactions néga...  ...         0.750000\n",
              "\n",
              "[1200 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Scale the submission data\n",
        "scaler = MinMaxScaler()\n",
        "col_to_scale = [\"raw_word_count\",\"token_count\",\"avg_chr_word\",\"avg_chr_token\"]\n",
        "#no need for the others because they already are on a scale from 0 to 1\n",
        "new_sub_df[col_to_scale]= scaler.fit_transform(new_sub_df[col_to_scale])\n",
        "\n",
        "new_sub_df "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "qwJv_YGM-2gm",
        "outputId": "bb91f4dd-3069-4cda-cac1-44add9d1137f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>raw_word_count</th>\n",
              "      <th>token_count</th>\n",
              "      <th>avg_chr_word</th>\n",
              "      <th>avg_chr_token</th>\n",
              "      <th>diversity_word</th>\n",
              "      <th>density_word</th>\n",
              "      <th>density_token</th>\n",
              "      <th>freq_word_list</th>\n",
              "      <th>freq_token_list</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nous dûmes nous excuser des propos que nous eû...</td>\n",
              "      <td>0.051282</td>\n",
              "      <td>0.061538</td>\n",
              "      <td>0.413793</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.374384</td>\n",
              "      <td>0.539130</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Et, paradoxalement, boire froid n'est pas la b...</td>\n",
              "      <td>0.044872</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.490421</td>\n",
              "      <td>0.573913</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ce n'est pas étonnant, car c'est une saison my...</td>\n",
              "      <td>0.044872</td>\n",
              "      <td>0.046154</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.695652</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Le corps de Golo lui-même, d'une essence aussi...</td>\n",
              "      <td>0.448718</td>\n",
              "      <td>0.476923</td>\n",
              "      <td>0.469349</td>\n",
              "      <td>0.636746</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.418605</td>\n",
              "      <td>0.612903</td>\n",
              "      <td>0.543860</td>\n",
              "      <td>0.677419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>C'est un phénomène qui trouve une accélération...</td>\n",
              "      <td>0.128205</td>\n",
              "      <td>0.138462</td>\n",
              "      <td>0.426332</td>\n",
              "      <td>0.695652</td>\n",
              "      <td>0.954545</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>Je vais parler au serveur et voir si on peut d...</td>\n",
              "      <td>0.070513</td>\n",
              "      <td>0.092308</td>\n",
              "      <td>0.286472</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>Il n'était pas comme tant de gens qui par pare...</td>\n",
              "      <td>0.467949</td>\n",
              "      <td>0.523077</td>\n",
              "      <td>0.450575</td>\n",
              "      <td>0.618926</td>\n",
              "      <td>0.826667</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>0.852941</td>\n",
              "      <td>0.596774</td>\n",
              "      <td>0.441176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>Ils deviennent dangereux pour notre économie.</td>\n",
              "      <td>0.025641</td>\n",
              "      <td>0.046154</td>\n",
              "      <td>0.643678</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>Son succès a généré beaucoup de réactions néga...</td>\n",
              "      <td>0.038462</td>\n",
              "      <td>0.061538</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  ...  freq_token_list\n",
              "id                                                       ...                 \n",
              "0     Nous dûmes nous excuser des propos que nous eû...  ...         0.250000\n",
              "1     Vous ne pouvez pas savoir le plaisir que j'ai ...  ...         0.000000\n",
              "2     Et, paradoxalement, boire froid n'est pas la b...  ...         0.400000\n",
              "3     Ce n'est pas étonnant, car c'est une saison my...  ...         0.666667\n",
              "4     Le corps de Golo lui-même, d'une essence aussi...  ...         0.677419\n",
              "...                                                 ...  ...              ...\n",
              "1195  C'est un phénomène qui trouve une accélération...  ...         0.555556\n",
              "1196  Je vais parler au serveur et voir si on peut d...  ...         0.333333\n",
              "1197  Il n'était pas comme tant de gens qui par pare...  ...         0.441176\n",
              "1198      Ils deviennent dangereux pour notre économie.  ...         0.666667\n",
              "1199  Son succès a généré beaucoup de réactions néga...  ...         0.750000\n",
              "\n",
              "[1200 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get it in correct form and predict\n",
        "X_sub = new_sub_df[[\"sentence\",\"raw_word_count\",\"token_count\",\"avg_chr_word\",\"avg_chr_token\",\n",
        "                    \"diversity_word\",\"density_word\",\"density_token\",\"freq_word_list\",\n",
        "            \"freq_token_list\"]]\n",
        "\n",
        "y_sub_lsvc = pipe_lsvc.predict(X_sub)\n"
      ],
      "metadata": {
        "id": "cUvFlwM6-4a4"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sub_df[\"difficulty\"] = y_sub_lsvc\n",
        "submission = new_sub_df.filter([\"id\",\"difficulty\"],axis=1)\n",
        "submission"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "LXEp8YDs_jnA",
        "outputId": "11844dbc-5f3c-4533-e9e1-184823f7c24b"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>A2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>C2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     difficulty\n",
              "id             \n",
              "0            C1\n",
              "1            B1\n",
              "2            C2\n",
              "3            C1\n",
              "4            C2\n",
              "...         ...\n",
              "1195         C2\n",
              "1196         A2\n",
              "1197         C2\n",
              "1198         C1\n",
              "1199         C2\n",
              "\n",
              "[1200 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "submission.to_csv('submission_05_apple_unil.csv') \n",
        "files.download('submission_05_apple_unil.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Hx2XfibLBJcn",
        "outputId": "52f49458-c534-4617-d6eb-4145cef6dba3"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b35ff53c-fa34-4fb3-becd-09d9366ed126\", \"submission_05_apple_unil.csv\", 8504)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Define classifier\n",
        "classifier_CV = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=10000, random_state=72)\n",
        "\n",
        "#Vectorizer\n",
        "tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer)\n",
        "\n",
        "#Column Transformer (to apply vectorizer to the right column)\n",
        "column_transformer = ColumnTransformer(\n",
        "    [(\"tfidf\", tfidf_vector, \"sentence\")],\n",
        "    remainder=\"passthrough\")\n",
        "\n",
        "# Create pipeline\n",
        "pipe_cv = Pipeline([(\"tfidf\",column_transformer),(\"classifier\", classifier_CV)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe_cv.fit(X_train, y_train)\n",
        "# Predictions\n",
        "#y_pred = pipe_cv.predict(X_test)\n",
        "\n",
        "# Evaluation - test set\n",
        "#evaluate(y_test, y_pred)\n",
        "\n",
        "#just token: \n",
        "#just words: 0.4792\n",
        "#everything: 0.4865, the time it takes to compute isn't worth it. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MYzjZGS0VC-",
        "outputId": "f0373bce-e7a5-4c55-ee0f-7fc771a7202c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf',\n",
              "                 ColumnTransformer(remainder='passthrough',\n",
              "                                   transformers=[('tfidf',\n",
              "                                                  TfidfVectorizer(tokenizer=<function spacy_tokenizer at 0x7f5a3554b9e0>),\n",
              "                                                  'sentence')])),\n",
              "                ('classifier',\n",
              "                 LogisticRegressionCV(cv=5, max_iter=10000, random_state=72))])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P4Y1DnjysrP",
        "outputId": "6e68d6a2-b6dc-440d-a782-f50484ea7d50"
      },
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "#Create a Gaussian Classifier\n",
        "random_for=RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "pipe_rf = Pipeline([(\"tfidf\",column_transformer),('feature_selection',SelectFromModel(LinearSVC(penalty=\"l2\"))),(\"model\", random_for)])\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "pipe_rf.fit(X_train,y_train)\n",
        "\n",
        "#y_pred=pipe.predict(X_test)\n",
        "#evaluate(y_test, y_pred)\n",
        "\n",
        "#just tokens:0.4365\n",
        "#just words: 0.4688"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf',\n",
              "                 ColumnTransformer(remainder='passthrough',\n",
              "                                   transformers=[('tfidf',\n",
              "                                                  TfidfVectorizer(tokenizer=<function spacy_tokenizer at 0x7f5a3554b9e0>),\n",
              "                                                  'sentence')])),\n",
              "                ('feature_selection', SelectFromModel(estimator=LinearSVC())),\n",
              "                ('model', RandomForestClassifier())])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "\n",
        "#Train the model\n",
        "lsvc = LinearSVC(verbose=0)\n",
        "\n",
        "pipe_lsvc = Pipeline([(\"tfidf\",column_transformer),(\"model\", lsvc)])\n",
        "pipe_lsvc.fit(X_train,y_train)\n",
        "y_pred=pipe.predict(X_test)\n",
        "evaluate(y_test, y_pred)\n",
        "#just token: 0.4344\n",
        "#just words: 0.4458\n",
        "#everything with no feature selection: 0.4865\n",
        "#everything with feature selection: 0.4865\n",
        "#but when doing the submission, it's lower....overfitting!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qXfhiiYkewG",
        "outputId": "3273d2ec-0247-493c-e546-b3b8ba760d45"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[99 31 24  8  1  0]\n",
            " [40 66 42  6  5  0]\n",
            " [24 39 61 21  6  8]\n",
            " [ 5  6 18 73 28 28]\n",
            " [ 2  3  6 36 84 29]\n",
            " [ 5  0 12 28 32 84]]\n",
            "ACCURACY SCORE:\n",
            "0.4865\n",
            "CLASSIFICATION REPORT:\n",
            "Precision:\t 0.486960\n",
            "Recall:\t 0.485811\n",
            "F1_Score:\t 0.485816\n"
          ]
        }
      ]
    }
  ]
}