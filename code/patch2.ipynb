{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "patch2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QScwR_sTi7xG"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1mUDx4uFpbS6jrD7lN-P7F7saefP_QJ31?usp=sharing)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMDP-YEodfnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eadb308-68f3-42c1-f2ad-9a4136d95b90"
      },
      "source": [
        "# Import required packages\n",
        "!python -m spacy download fr_core_news_sm\n",
        "#import fr_core_news_sm\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        " "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fr_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.10)\n",
            "Building wheels for collected packages: fr-core-news-sm\n",
            "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-py3-none-any.whl size=14727026 sha256=8b14c02e394033fb4b200259c9c242eabed1f7ec274cde85ba2e34a61b86e342\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-r9oboz18/wheels/c9/a6/ea/0778337c34660027ee67ef3a91fb9d3600b76777a912ea1c24\n",
            "Successfully built fr-core-news-sm\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5YYODCIdjJs"
      },
      "source": [
        "# Import additional packages\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "import string\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "\n",
        "from spacy.lang.fr.stop_words import STOP_WORDS\n",
        "from spacy.lang.fr.examples import sentences \n",
        "from spacy.lang.fr import French\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "uAQg9ugrdrS6",
        "outputId": "af382945-0f76-4821-bb6e-674bfd23c1c8"
      },
      "source": [
        "path = \"https://raw.githubusercontent.com/Lirette2/DMML2021_Apple/main/data/training_data.csv\"\n",
        "df = pd.read_csv(path, index_col=0)\n",
        "df.head()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Le test de niveau en français est sur le site ...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             sentence difficulty\n",
              "id                                                              \n",
              "0   Les coûts kilométriques réels peuvent diverger...         C1\n",
              "1   Le bleu, c'est ma couleur préférée mais je n'a...         A1\n",
              "2   Le test de niveau en français est sur le site ...         A1\n",
              "3            Est-ce que ton mari est aussi de Boston?         A1\n",
              "4   Dans les écoles de commerce, dans les couloirs...         B1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvPY_lQydtnp",
        "outputId": "7697daa3-580c-419f-ad95-084cc62db212"
      },
      "source": [
        "df.info()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 4800 entries, 0 to 4799\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   sentence    4800 non-null   object\n",
            " 1   difficulty  4800 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 112.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BouzxX3ndvik",
        "outputId": "ad761c82-f4c9-452b-dad7-9e44bf512a22"
      },
      "source": [
        "# Base rate: the data-set is a bit balanced!\n",
        "df.difficulty.value_counts()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "A1    813\n",
              "C2    807\n",
              "C1    798\n",
              "A2    795\n",
              "B1    795\n",
              "B2    792\n",
              "Name: difficulty, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "OxATHOC2dxPh",
        "outputId": "7369386d-e0d8-45b6-b355-9ffd7bc12d40"
      },
      "source": [
        "difficulty_count = df.groupby(\"difficulty\").count()\n",
        "plt.bar(difficulty_count.index.values, difficulty_count[\"sentence\"])\n",
        "plt.xlabel(\"Difficulty\")\n",
        "plt.ylabel(\"Number of Sentences\")\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWAbLqJpfA0F",
        "outputId": "8ce3ff2f-9239-494e-af85-cdee29222a74"
      },
      "source": [
        "round(df.difficulty.value_counts().max()/ len(df), 4)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1694"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daGEGXdFfESw"
      },
      "source": [
        "### tokening the date with spaCy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cLA0BmpVfJEI",
        "outputId": "60e68a8a-cd6b-41a7-a96b-21df637a463c"
      },
      "source": [
        "# Create a list of punctuation marks\n",
        "punctuations = string.punctuation\n",
        "punctuations"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQBHplsRfLXk",
        "outputId": "95207e35-cc92-4c61-8093-255f0eac8b77"
      },
      "source": [
        "# Create a list of stopwords\n",
        "#stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
        "stop_words = spacy.lang.fr.stop_words.STOP_WORDS\n",
        "\n",
        "list(stop_words)[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"t'\",\n",
              " 'nôtres',\n",
              " 'té',\n",
              " 'hum',\n",
              " 'pendant',\n",
              " 'vous-mêmes',\n",
              " 'tiennes',\n",
              " 'vive',\n",
              " 'mes',\n",
              " 'directe']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC6QJzQffNkL"
      },
      "source": [
        "# Load French language model\n",
        "import fr_core_news_sm\n",
        "#sp = spacy.load('en_core_web_sm')\n",
        "sp = fr_core_news_sm.load()\n",
        "\n",
        "# Create tokenizer function\n",
        "def spacy_tokenizer(sentence):\n",
        "    # Create token object, which is used to create documents with linguistic annotations.\n",
        "    mytokens = sp(sentence)\n",
        "\n",
        "    # Lemmatize each token and convert each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() for word in mytokens ]\n",
        "    ## alternative way\n",
        "    # mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "\n",
        "    # Remove stop words and punctuation\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    # Return preprocessed list of tokens\n",
        "    return mytokens\n",
        "\n"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAbdvIavfP5G",
        "outputId": "a464d648-a1cd-45e9-dc77-946e54419000"
      },
      "source": [
        "# Example\n",
        "#New_sentence = df[\"sentence\"].sample()\n",
        "New_sentence = df[\"sentence\"].head()\n",
        "New_sentence.values[0]\n",
        "spacy_tokenizer(New_sentence.values[0])\n"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['coût',\n",
              " 'kilométrique',\n",
              " 'réel',\n",
              " 'pouvoir',\n",
              " 'diverger',\n",
              " 'sensiblemer',\n",
              " 'valeur',\n",
              " 'moyenner',\n",
              " 'fonction',\n",
              " 'moyen',\n",
              " 'transport',\n",
              " 'utiliser',\n",
              " 'taux',\n",
              " 'occupation',\n",
              " 'taux',\n",
              " 'remplissage',\n",
              " 'infrastructure',\n",
              " 'utiliser',\n",
              " 'topographie',\n",
              " 'ligne',\n",
              " 'flux',\n",
              " 'trafic',\n",
              " 'etc.']"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB7SbUOafRXZ"
      },
      "source": [
        "#### **** ***************** **** ####\n",
        "#### **** RAW TEXT FEATURES **** ####\n",
        "#### **** ***************** **** ####\n",
        "\n",
        "# Count tokens per sentence\n",
        "def count_token(sent):\n",
        "  return(len(spacy_tokenizer(sent))) #spacy_tokenizer() to get tokens, len() to count them\n",
        "\n",
        "# Count raw words per sentence\n",
        "def count_words(sent):\n",
        "  return(len(sent.split())) #split() gives us individual words, len() counts them\n",
        "\n",
        "#Get average character length of word\n",
        "def count_avg_word_character(sent):\n",
        "  words = sent.split()\n",
        "  return(sum(len(word) for word in words) / len(words))\n",
        "\n",
        "def count_avg_token_character(sent):\n",
        "  words = spacy_tokenizer(sent)\n",
        "  if len(words) == 0:\n",
        "    return(0)\n",
        "  else:\n",
        "    return(sum(len(word) for word in words) / len(words))"
      ],
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Czbuy7JkXJnB"
      },
      "source": [
        "#### **** **************** **** ####\n",
        "#### **** LEXICAL FEATURES **** ####\n",
        "#### **** **************** **** ####\n",
        "\n",
        "# Lexical Diversity\n",
        "def lex_div_word(sent):\n",
        "  total_number_word = len(sent.split())\n",
        "  unique = set(sent.split())\n",
        "  return(len(unique)/total_number_word)\n",
        "#We don't apply for token, as the goal of the tokenzization is to be left with \n",
        "#unique tokens\n",
        "#For tokens, we should apply to the whole text as done by tfidf_vector\n",
        "\n",
        "# Lexical Density\n",
        "def lex_den_tokens(sent):\n",
        "  st = spacy_tokenizer(sent)\n",
        "  string = \" \".join([str(item) for item in st])\n",
        "  x = sp(string)\n",
        "  counter = 0 \n",
        "  for token in x:\n",
        "    if token.pos_ == \"NOUN\" or token.pos_ == \"ADJ\" or token.pos_ == \"VERB\" or token.pos_ == \"ADV\":\n",
        "      counter = counter + 1\n",
        "  if len(st) == 0:\n",
        "    return(0)\n",
        "  else:\n",
        "    return(counter/len(st))\n",
        "\n",
        "def lex_den_words(sent):\n",
        "  x = sp(sent)\n",
        "  counter = 0 \n",
        "  for token in x:\n",
        "    if token.pos_ == \"NOUN\" or token.pos_ == \"ADJ\" or token.pos_ == \"VERB\" or token.pos_ == \"ADV\":\n",
        "      counter = counter + 1\n",
        "  return(counter/len(x))\n",
        "\n",
        "# Words NOT in frequent list\n",
        "path = \"https://raw.githubusercontent.com/Lirette2/DMML2021_Apple/main/data/list_words.csv\"\n",
        "words = pd.read_csv(path, index_col=0)\n",
        "\n",
        "\n",
        "def words_list(sent):\n",
        "  unique = set(sent.split())\n",
        "  counter = 0\n",
        "  for word_in_sentence in unique:\n",
        "    for word_in_list in words.Mots:\n",
        "      if word_in_sentence == word_in_list:\n",
        "        counter = counter + 1\n",
        "        break#we stop comparing once the word in found, to make it faster\n",
        "  return(counter/len(unique))\n",
        "\n",
        "\n",
        "def token_list(sent):\n",
        "  unique = spacy_tokenizer(sent)\n",
        "  counter = 0\n",
        "  for word_in_sentence in unique:\n",
        "    for word_in_list in words.Mots:\n",
        "      if word_in_sentence == word_in_list:\n",
        "        counter = counter + 1\n",
        "        break#we stop comparing once the word in found, to make it faster\n",
        "  return(counter/len(unique))\n"
      ],
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qJEbTBFhM3J7",
        "outputId": "f25f66f8-824c-480d-8c8a-e83cc4273922"
      },
      "source": [
        "raw_word_count = pd.Series(df.sentence.apply(count_words),name=\"raw_word_count\")\n",
        "token_count = pd.Series(df.sentence.apply(count_token),name=\"token_count\")\n",
        "avg_chr_word = pd.Series(df.sentence.apply(count_avg_word_character),name=\"avg_chr_word\")\n",
        "avg_chr_token = pd.Series(df.sentence.apply(count_avg_token_character),name=\"avg_chr_token\")\n",
        "diversity_word = pd.Series(df.sentence.apply(lex_div_word),name=\"diversity_word\")\n",
        "density_word = pd.Series(df.sentence.apply(lex_den_words),name=\"density_word\")\n",
        "density_token = pd.Series(df.sentence.apply(lex_den_tokens),name=\"density_token\")\n",
        "freq_word_list = pd.Series(df.sentence.apply(words_not_list),name=\"freq_word_list\")\n",
        "freq_token_list = pd.Series(df.sentence.apply(words_list),name=\"freq_token_list\")\n",
        "\n",
        "new_df = pd.concat([df,raw_word_count,token_count,avg_chr_word,avg_chr_token,\n",
        "                    diversity_word,density_word,density_token,freq_word_list,freq_token_list],axis=1)\n",
        "new_df"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>raw_word_count</th>\n",
              "      <th>token_count</th>\n",
              "      <th>avg_chr_word</th>\n",
              "      <th>avg_chr_token</th>\n",
              "      <th>diversity_word</th>\n",
              "      <th>density_word</th>\n",
              "      <th>density_token</th>\n",
              "      <th>freq_word_list</th>\n",
              "      <th>freq_token_list</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
              "      <td>C1</td>\n",
              "      <td>38</td>\n",
              "      <td>23</td>\n",
              "      <td>5.736842</td>\n",
              "      <td>7.434783</td>\n",
              "      <td>0.763158</td>\n",
              "      <td>0.488889</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.793103</td>\n",
              "      <td>0.206897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
              "      <td>A1</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>4.250000</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.416667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Le test de niveau en français est sur le site ...</td>\n",
              "      <td>A1</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>4.153846</td>\n",
              "      <td>5.833333</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>A1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>4.125000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
              "      <td>B1</td>\n",
              "      <td>34</td>\n",
              "      <td>18</td>\n",
              "      <td>5.176471</td>\n",
              "      <td>5.611111</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>C'est pourquoi, il décida de remplacer les hab...</td>\n",
              "      <td>B2</td>\n",
              "      <td>26</td>\n",
              "      <td>12</td>\n",
              "      <td>5.384615</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.576923</td>\n",
              "      <td>0.423077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>Il avait une de ces pâleurs splendides qui don...</td>\n",
              "      <td>C1</td>\n",
              "      <td>21</td>\n",
              "      <td>10</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>5.700000</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>Et le premier samedi de chaque mois, venez ren...</td>\n",
              "      <td>A2</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>4.785714</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.461538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>Les coûts liés à la journalisation n'étant pas...</td>\n",
              "      <td>C2</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>6.093750</td>\n",
              "      <td>8.500000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.540541</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.678571</td>\n",
              "      <td>0.321429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>Sur le sable, la mer haletait de toute la resp...</td>\n",
              "      <td>C2</td>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "      <td>4.647059</td>\n",
              "      <td>6.250000</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4800 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  ... freq_token_list\n",
              "id                                                       ...                \n",
              "0     Les coûts kilométriques réels peuvent diverger...  ...        0.206897\n",
              "1     Le bleu, c'est ma couleur préférée mais je n'a...  ...        0.416667\n",
              "2     Le test de niveau en français est sur le site ...  ...        0.500000\n",
              "3              Est-ce que ton mari est aussi de Boston?  ...        0.750000\n",
              "4     Dans les écoles de commerce, dans les couloirs...  ...        0.285714\n",
              "...                                                 ...  ...             ...\n",
              "4795  C'est pourquoi, il décida de remplacer les hab...  ...        0.423077\n",
              "4796  Il avait une de ces pâleurs splendides qui don...  ...        0.250000\n",
              "4797  Et le premier samedi de chaque mois, venez ren...  ...        0.461538\n",
              "4798  Les coûts liés à la journalisation n'étant pas...  ...        0.321429\n",
              "4799  Sur le sable, la mer haletait de toute la resp...  ...        0.400000\n",
              "\n",
              "[4800 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ywssd_eDU5hy",
        "outputId": "a87b796e-7581-4509-f275-ecd89680b846"
      },
      "source": [
        "#Scale the data\n",
        "scaler = MinMaxScaler()\n",
        "col_to_scale = [\"raw_word_count\",\"token_count\",\"avg_chr_word\",\"avg_chr_token\"]\n",
        "#no need for the others because they already are on a scale from 0 to 1\n",
        "\n",
        "new_df[col_to_scale]= scaler.fit_transform(new_df[col_to_scale])\n",
        "new_df"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>raw_word_count</th>\n",
              "      <th>token_count</th>\n",
              "      <th>avg_chr_word</th>\n",
              "      <th>avg_chr_token</th>\n",
              "      <th>diversity_word</th>\n",
              "      <th>density_word</th>\n",
              "      <th>density_token</th>\n",
              "      <th>freq_word_list</th>\n",
              "      <th>freq_token_list</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
              "      <td>C1</td>\n",
              "      <td>0.140152</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.339713</td>\n",
              "      <td>0.619565</td>\n",
              "      <td>0.763158</td>\n",
              "      <td>0.488889</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.793103</td>\n",
              "      <td>0.206897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
              "      <td>A1</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.204545</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.416667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Le test de niveau en français est sur le site ...</td>\n",
              "      <td>A1</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.195804</td>\n",
              "      <td>0.486111</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>A1</td>\n",
              "      <td>0.026515</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.193182</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
              "      <td>B1</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.144</td>\n",
              "      <td>0.288770</td>\n",
              "      <td>0.467593</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>C'est pourquoi, il décida de remplacer les hab...</td>\n",
              "      <td>B2</td>\n",
              "      <td>0.094697</td>\n",
              "      <td>0.096</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.576923</td>\n",
              "      <td>0.423077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>Il avait une de ces pâleurs splendides qui don...</td>\n",
              "      <td>C1</td>\n",
              "      <td>0.075758</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.242424</td>\n",
              "      <td>0.475000</td>\n",
              "      <td>0.952381</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>Et le premier samedi de chaque mois, venez ren...</td>\n",
              "      <td>A2</td>\n",
              "      <td>0.049242</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.253247</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.461538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>Les coûts liés à la journalisation n'étant pas...</td>\n",
              "      <td>C2</td>\n",
              "      <td>0.117424</td>\n",
              "      <td>0.128</td>\n",
              "      <td>0.372159</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.540541</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.678571</td>\n",
              "      <td>0.321429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>Sur le sable, la mer haletait de toute la resp...</td>\n",
              "      <td>C2</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.064</td>\n",
              "      <td>0.240642</td>\n",
              "      <td>0.520833</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4800 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  ... freq_token_list\n",
              "id                                                       ...                \n",
              "0     Les coûts kilométriques réels peuvent diverger...  ...        0.206897\n",
              "1     Le bleu, c'est ma couleur préférée mais je n'a...  ...        0.416667\n",
              "2     Le test de niveau en français est sur le site ...  ...        0.500000\n",
              "3              Est-ce que ton mari est aussi de Boston?  ...        0.750000\n",
              "4     Dans les écoles de commerce, dans les couloirs...  ...        0.285714\n",
              "...                                                 ...  ...             ...\n",
              "4795  C'est pourquoi, il décida de remplacer les hab...  ...        0.423077\n",
              "4796  Il avait une de ces pâleurs splendides qui don...  ...        0.250000\n",
              "4797  Et le premier samedi de chaque mois, venez ren...  ...        0.461538\n",
              "4798  Les coûts liés à la journalisation n'étant pas...  ...        0.321429\n",
              "4799  Sur le sable, la mer haletait de toute la resp...  ...        0.400000\n",
              "\n",
              "[4800 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMiQYs9XfU0I"
      },
      "source": [
        "## classification of level using logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4mcl9ptvfXzi",
        "outputId": "d9edad3b-9d99-4ead-fb43-4af5c9a9688a"
      },
      "source": [
        "# Select features\n",
        "X = new_df[[\"sentence\",\"raw_word_count\",\"token_count\",\"avg_chr_word\",\"avg_chr_token\",\n",
        "                    \"diversity_word\",\"density_word\",\"density_token\",\"freq_word_list\",\n",
        "            \"freq_token_list\"]]# the features we want to analyze\n",
        "\n",
        "ylabels = new_df['difficulty'] # the labels, or answers, we want to test against\n",
        "\n",
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=1234, stratify=ylabels)\n",
        "\n",
        "X_train"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>raw_word_count</th>\n",
              "      <th>token_count</th>\n",
              "      <th>avg_chr_word</th>\n",
              "      <th>avg_chr_token</th>\n",
              "      <th>diversity_word</th>\n",
              "      <th>density_word</th>\n",
              "      <th>density_token</th>\n",
              "      <th>freq_word_list</th>\n",
              "      <th>freq_token_list</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>962</th>\n",
              "      <td>Le réalisateur m'a d'abord demandé de me mettr...</td>\n",
              "      <td>0.037879</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.645833</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.454545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1886</th>\n",
              "      <td>Après quelques mois de cette pauvreté noble, a...</td>\n",
              "      <td>0.109848</td>\n",
              "      <td>0.112</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.517857</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.586207</td>\n",
              "      <td>0.413793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2721</th>\n",
              "      <td>L'indicateur n'était que de 40% chez les femme...</td>\n",
              "      <td>0.034091</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.245455</td>\n",
              "      <td>0.483333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1025</th>\n",
              "      <td>L'objectif de ce type de voyage est d'être act...</td>\n",
              "      <td>0.094697</td>\n",
              "      <td>0.096</td>\n",
              "      <td>0.241259</td>\n",
              "      <td>0.527778</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.482759</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4048</th>\n",
              "      <td>Et, en France, beaucoup moins de filles que de...</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.276680</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.384615</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3693</th>\n",
              "      <td>Je vais prendre ma douche dans ma salle-de-bain.</td>\n",
              "      <td>0.026515</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.284091</td>\n",
              "      <td>0.645833</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3408</th>\n",
              "      <td>Après l'éruption de 1754, la plus grosse connu...</td>\n",
              "      <td>0.132576</td>\n",
              "      <td>0.128</td>\n",
              "      <td>0.275253</td>\n",
              "      <td>0.546875</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.655172</td>\n",
              "      <td>0.344828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4289</th>\n",
              "      <td>Léonard est initié par Verrocchio aux nombreus...</td>\n",
              "      <td>0.117424</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.369318</td>\n",
              "      <td>0.644444</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.472222</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3312</th>\n",
              "      <td>On en trouve des exemples dans l'ouvrage \"L'in...</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.432727</td>\n",
              "      <td>0.694444</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.360000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>On peut aussi aller au théâtre, dans les musée...</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.189394</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.454545</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3840 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  ...  freq_token_list\n",
              "id                                                       ...                 \n",
              "962   Le réalisateur m'a d'abord demandé de me mettr...  ...         0.454545\n",
              "1886  Après quelques mois de cette pauvreté noble, a...  ...         0.413793\n",
              "2721  L'indicateur n'était que de 40% chez les femme...  ...         0.400000\n",
              "1025  L'objectif de ce type de voyage est d'être act...  ...         0.625000\n",
              "4048  Et, en France, beaucoup moins de filles que de...  ...         0.363636\n",
              "...                                                 ...  ...              ...\n",
              "3693   Je vais prendre ma douche dans ma salle-de-bain.  ...         0.285714\n",
              "3408  Après l'éruption de 1754, la plus grosse connu...  ...         0.344828\n",
              "4289  Léonard est initié par Verrocchio aux nombreus...  ...         0.333333\n",
              "3312  On en trouve des exemples dans l'ouvrage \"L'in...  ...         0.360000\n",
              "269   On peut aussi aller au théâtre, dans les musée...  ...         0.454545\n",
              "\n",
              "[3840 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYn0f20UfZBz",
        "outputId": "4b19ba00-de6c-4f1b-bdd3-e5fa2d32ff5a"
      },
      "source": [
        "y_train\n"
      ],
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "962     B1\n",
              "1886    C1\n",
              "2721    A2\n",
              "1025    B1\n",
              "4048    B2\n",
              "        ..\n",
              "3693    A1\n",
              "3408    B1\n",
              "4289    C2\n",
              "3312    C2\n",
              "269     A1\n",
              "Name: difficulty, Length: 3840, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF7mS7lLfaXk",
        "outputId": "d29f0594-c6fa-4743-cbc0-0604ca9e65af"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Define classifier\n",
        "classifier = LogisticRegression(multi_class=\"multinomial\",max_iter=1000)\n",
        "\n",
        "#Vectorizer\n",
        "tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer)\n",
        "\n",
        "#Column Transformer (to apply vectorizer to the right column)\n",
        "column_transformer = ColumnTransformer(\n",
        "    [(\"tfidf\", tfidf_vector, \"sentence\")],\n",
        "    remainder=\"passthrough\")\n",
        "\n",
        "# Create pipeline\n",
        "pipe = Pipeline([(\"tfidf\",column_transformer),(\"classifier\", classifier)])\n",
        "\n",
        "# Fit model on training set\n",
        "pipe.fit(X_train, y_train)\n"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf',\n",
              "                 ColumnTransformer(remainder='passthrough',\n",
              "                                   transformers=[('tfidf',\n",
              "                                                  TfidfVectorizer(tokenizer=<function spacy_tokenizer at 0x7f44f63848c0>),\n",
              "                                                  'sentence')])),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(max_iter=1000, multi_class='multinomial'))])"
            ]
          },
          "metadata": {},
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iaGbtXRfTze"
      },
      "source": [
        "# Evaluate the model\n",
        "def evaluate(test, pred):\n",
        "  precision = precision_score(test, pred,average=None)\n",
        "  recall = recall_score(test, pred, average=None)\n",
        "  f1= f1_score(test, pred, average=None)\n",
        "  print(f'CONFUSION MATRIX:\\n{confusion_matrix(test, pred)}')\n",
        "  print(f\"ACCURACY SCORE:\\n{accuracy_score(test, pred) :.4f}\")\n",
        "  print(f'CLASSIFICATION REPORT:')\n",
        "  print(\"Precision:\\t {0:4f}\".format(precision_score(test, pred,average=\"macro\"))) \n",
        "  print(\"Recall:\\t {0:4f}\".format(recall_score(test, pred, average=\"macro\")))\n",
        "  print(\"F1_Score:\\t {0:4f}\".format(f1_score(test, pred, average=\"macro\")))\n"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAve0ev8fFZT",
        "outputId": "28068eb3-946d-4901-f1a8-3e084d9bf6e5"
      },
      "source": [
        "# Predictions\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "# Evaluation - test set\n",
        "evaluate(y_test, y_pred)"
      ],
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[101  27  25   8   1   1]\n",
            " [ 44  61  45   4   4   1]\n",
            " [ 20  40  64  19   8   8]\n",
            " [  6   7  18  69  28  30]\n",
            " [  4   3  10  36  71  36]\n",
            " [  3   0  12  21  30  95]]\n",
            "ACCURACY SCORE:\n",
            "0.4802\n",
            "CLASSIFICATION REPORT:\n",
            "Precision:\t 0.478718\n",
            "Recall:\t 0.479386\n",
            "F1_Score:\t 0.478020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P4Y1DnjysrP",
        "outputId": "88a43ca6-48b2-451b-ab24-2ac8781ed0be"
      },
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "random_for=RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "pipe = Pipeline([(\"tfidf\",column_transformer),(\"model\", random_for)])\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "pipe.fit(X_train,y_train)\n",
        "\n",
        "y_pred=pipe.predict(X_test)\n",
        "evaluate(y_test, y_pred)"
      ],
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[118  27  16   2   0   0]\n",
            " [ 51  67  37   3   1   0]\n",
            " [ 24  44  68  10   7   6]\n",
            " [  8   3  26  65  35  21]\n",
            " [ 10   7  14  34  68  27]\n",
            " [  3   5  18  27  42  66]]\n",
            "ACCURACY SCORE:\n",
            "0.4708\n",
            "CLASSIFICATION REPORT:\n",
            "Precision:\t 0.470773\n",
            "Recall:\t 0.469886\n",
            "F1_Score:\t 0.466148\n"
          ]
        }
      ]
    }
  ]
}